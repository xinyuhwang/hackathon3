{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Use OctoAI LLM\n",
    "from langchain.llms.octoai_endpoint import OctoAIEndpoint\n",
    "# Make sure you've set OCTOAI_API_TOKEN in your environment\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = OctoAIEndpoint(\n",
    "    endpoint_url=\"https://text.octoai.run/v1/chat/completions\",\n",
    "    model_kwargs={\n",
    "        # \"model\": \"llama-2-70b-chat-fp16\",\n",
    "        \"model\": \"mixtral-8x7b-instruct-fp16\",\n",
    "        \"messages\": [ {\"role\": \"system\", \"content\": \"Below is an instruction that describes a task.\"} ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    ")\n",
    "\n",
    "actor_query = \"How can I ask for directions in German?\"\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "output = model(_input.to_string())\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_factors(n):\n",
    "    i = 2\n",
    "    factors = []\n",
    "    while i * i <= n:\n",
    "        if n % i:\n",
    "            i += 1\n",
    "        else:\n",
    "            n //= i\n",
    "            factors.append(i)\n",
    "    if n > 1:\n",
    "        factors.append(n)\n",
    "    return factors\n",
    "\n",
    "print(prime_factors(315)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OctoAIEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = OctoAIEmbeddings(\n",
    "        endpoint_url=\"https://text.octoai.run/v1/embeddings\",\n",
    "        octoai_api_token=os.getenv(\"OCTOAI_API_TOKEN\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"one\", \"two\", \"three\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = embed._compute_embeddings(texts, \"compute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
